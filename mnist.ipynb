{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=(1,1))\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=(1,1))\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "        self.globalMaxPool = nn.MaxPool2d(7, 1)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))        #卷积\n",
    "        x = self.pool1(x)                #池化\n",
    "        x = F.relu(self.conv2(x))        #卷积\n",
    "        x = self.pool2(x)                #池化\n",
    "        x = F.relu(self.conv3(x))        #卷积\n",
    "        x = self.globalMaxPool(x)        #池化\n",
    "        x = x.view(-1, 64*1*1)            #将输出reshape为1维\n",
    "        x = self.fc(x)                    #全连接\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7840000\n"
     ]
    }
   ],
   "source": [
    "train_images_idx3_ubyte_file = 'train-images.idx3-ubyte' # 训练图片数据\n",
    "train_labels_idx1_ubyte_file = 'train-labels.idx1-ubyte' # 训练标签数据\n",
    "test_images_idx3_ubyte_file = 't10k-images.idx3-ubyte'   # 测试图片数据\n",
    "test_labels_idx1_ubyte_file = 't10k-labels.idx1-ubyte'   # 测试标签数据\n",
    "\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii'\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(image_size) + 'B'\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images\n",
    "\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels\n",
    "\n",
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "\n",
    "train_images = load_train_images()\n",
    "train_labels = load_train_labels()\n",
    "test_images = load_test_images()\n",
    "test_labels = load_test_labels()\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=1) / 255.0    #数据预处理\n",
    "train_labels = train_labels.astype('int')\n",
    "test_images = np.expand_dims(test_images, axis=1) / 255.0\n",
    "test_labels = test_labels.astype('int')\n",
    "\n",
    "print(test_images.size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "net = Net()        #创建Net()对象\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    #设置计算设备，cpu或gpu\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()    #损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)    #优化器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.001\n",
      "[1,    51] loss: 0.058\n",
      "[1,   101] loss: 0.058\n",
      "[1,   151] loss: 0.057\n",
      "[1,   201] loss: 0.057\n",
      "[1,   251] loss: 0.057\n",
      "[1,   301] loss: 0.057\n",
      "[1,   351] loss: 0.057\n",
      "[1,   401] loss: 0.057\n",
      "[1,   451] loss: 0.057\n",
      "[1,   501] loss: 0.057\n",
      "[1,   551] loss: 0.057\n",
      "[2,     1] loss: 0.001\n",
      "[2,    51] loss: 0.056\n",
      "[2,   101] loss: 0.056\n",
      "[2,   151] loss: 0.056\n",
      "[2,   201] loss: 0.055\n",
      "[2,   251] loss: 0.055\n",
      "[2,   301] loss: 0.054\n",
      "[2,   351] loss: 0.053\n",
      "[2,   401] loss: 0.051\n",
      "[2,   451] loss: 0.048\n",
      "[2,   501] loss: 0.045\n",
      "[2,   551] loss: 0.040\n",
      "[3,     1] loss: 0.001\n",
      "[3,    51] loss: 0.027\n",
      "[3,   101] loss: 0.021\n",
      "[3,   151] loss: 0.018\n",
      "[3,   201] loss: 0.014\n",
      "[3,   251] loss: 0.012\n",
      "[3,   301] loss: 0.011\n",
      "[3,   351] loss: 0.010\n",
      "[3,   401] loss: 0.009\n",
      "[3,   451] loss: 0.009\n",
      "[3,   501] loss: 0.008\n",
      "[3,   551] loss: 0.008\n",
      "[4,     1] loss: 0.000\n",
      "[4,    51] loss: 0.007\n",
      "[4,   101] loss: 0.007\n",
      "[4,   151] loss: 0.008\n",
      "[4,   201] loss: 0.006\n",
      "[4,   251] loss: 0.006\n",
      "[4,   301] loss: 0.006\n",
      "[4,   351] loss: 0.006\n",
      "[4,   401] loss: 0.005\n",
      "[4,   451] loss: 0.006\n",
      "[4,   501] loss: 0.006\n",
      "[4,   551] loss: 0.006\n",
      "[5,     1] loss: 0.000\n",
      "[5,    51] loss: 0.005\n",
      "[5,   101] loss: 0.005\n",
      "[5,   151] loss: 0.006\n",
      "[5,   201] loss: 0.005\n",
      "[5,   251] loss: 0.005\n",
      "[5,   301] loss: 0.005\n",
      "[5,   351] loss: 0.005\n",
      "[5,   401] loss: 0.004\n",
      "[5,   451] loss: 0.005\n",
      "[5,   501] loss: 0.005\n",
      "[5,   551] loss: 0.005\n",
      "[6,     1] loss: 0.000\n",
      "[6,    51] loss: 0.004\n",
      "[6,   101] loss: 0.005\n",
      "[6,   151] loss: 0.005\n",
      "[6,   201] loss: 0.004\n",
      "[6,   251] loss: 0.004\n",
      "[6,   301] loss: 0.004\n",
      "[6,   351] loss: 0.004\n",
      "[6,   401] loss: 0.004\n",
      "[6,   451] loss: 0.004\n",
      "[6,   501] loss: 0.004\n",
      "[6,   551] loss: 0.004\n",
      "[7,     1] loss: 0.000\n",
      "[7,    51] loss: 0.004\n",
      "[7,   101] loss: 0.004\n",
      "[7,   151] loss: 0.004\n",
      "[7,   201] loss: 0.004\n",
      "[7,   251] loss: 0.003\n",
      "[7,   301] loss: 0.004\n",
      "[7,   351] loss: 0.003\n",
      "[7,   401] loss: 0.003\n",
      "[7,   451] loss: 0.004\n",
      "[7,   501] loss: 0.004\n",
      "[7,   551] loss: 0.004\n",
      "[8,     1] loss: 0.000\n",
      "[8,    51] loss: 0.003\n",
      "[8,   101] loss: 0.004\n",
      "[8,   151] loss: 0.004\n",
      "[8,   201] loss: 0.003\n",
      "[8,   251] loss: 0.003\n",
      "[8,   301] loss: 0.003\n",
      "[8,   351] loss: 0.003\n",
      "[8,   401] loss: 0.003\n",
      "[8,   451] loss: 0.003\n",
      "[8,   501] loss: 0.003\n",
      "[8,   551] loss: 0.003\n",
      "[9,     1] loss: 0.000\n",
      "[9,    51] loss: 0.003\n",
      "[9,   101] loss: 0.003\n",
      "[9,   151] loss: 0.003\n",
      "[9,   201] loss: 0.003\n",
      "[9,   251] loss: 0.003\n",
      "[9,   301] loss: 0.003\n",
      "[9,   351] loss: 0.003\n",
      "[9,   401] loss: 0.003\n",
      "[9,   451] loss: 0.003\n",
      "[9,   501] loss: 0.003\n",
      "[9,   551] loss: 0.003\n",
      "[10,     1] loss: 0.000\n",
      "[10,    51] loss: 0.003\n",
      "[10,   101] loss: 0.003\n",
      "[10,   151] loss: 0.003\n",
      "[10,   201] loss: 0.003\n",
      "[10,   251] loss: 0.002\n",
      "[10,   301] loss: 0.003\n",
      "[10,   351] loss: 0.003\n",
      "[10,   401] loss: 0.002\n",
      "[10,   451] loss: 0.003\n",
      "[10,   501] loss: 0.003\n",
      "[10,   551] loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "batch_size = 100\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(60000/batch_size)):\n",
    "        start_index = i*batch_size\n",
    "        inputs = torch.from_numpy(train_images[start_index:start_index+batch_size])\n",
    "        labels = torch.from_numpy(train_labels[start_index:start_index+batch_size])\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "\n",
    "        labels = labels.to(torch.int64)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 93.35%\n"
     ]
    }
   ],
   "source": [
    "test_num = 10000\n",
    "correct = 0\n",
    "for i in range(int(test_num/batch_size)):\n",
    "    start_index = i*batch_size\n",
    "    test_inputs = torch.from_numpy(test_images[start_index:start_index+batch_size]).float()\n",
    "    test_inputs = test_inputs.to(device)\n",
    "    outputs = net(test_inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    for j in range(batch_size):\n",
    "        if(predicted[j] == test_labels[start_index+j]):\n",
    "            correct += 1\n",
    "print(f\"Model accuracy on test set: {correct/test_num * 100:.2f}%\")\n",
    "\n",
    "save_path = './net.pth'\n",
    "torch.save(net.state_dict(), save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# 设已训练好的网络模型为 net\n",
    "torch_model_path = 'net.pth'\n",
    "onnx_model_path = \"mnist_model.onnx\"\n",
    "\n",
    "# torch 模型参数保存再加载到新的 model 中，避免报错\n",
    "torch.save(net.state_dict(), torch_model_path)\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"net.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 使用TorchScript来跟踪并导出模型\n",
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "traced_model = torch.jit.trace(model, input_tensor)\n",
    "traced_model.save(\"mnist_model.pt\")\n",
    "\n",
    "# 创建一个样本输入，大小需要与模型的输入层相匹配\n",
    "sample_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# 导出 onnx 模型\n",
    "torch.onnx.export(model, sample_input, onnx_model_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
