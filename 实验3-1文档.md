# 实验3-1：深度学习编译器：TVM

### 实验名称

深度学习编译器：TVM

### 实验目的

1. 了解深度学习编译器TVM的基本原理
1. 掌握TVM环境的基本配置方法
1. 使用TVM编译不同框架下的深度学习模型

### 实验任务

1. 配置TVM运行环境
1. 编译`darknet`框架下的`YOLOv3`算法

### 实验结果

![img](https://course.educg.net/exp/assets/sphx_glr_from_darknet_001.png)

### 实验分析

1. 涉及知识点：

   - TVM深度学习编译器的基本原理

   - TVM的设计理念

     - TVM介绍

       ApacheTVM是一个开源的机器学习编译框架，用于CPU、GPU和机器学习的加速。他的设计目标是为了使得机器学习工程师可以在不同的硬件后端高效地优化和运行计算过程。

     - TVM概述和模型优化

       下图展示了机器学习模型通过TVM进行优化的过程

       ![img](https://course.educg.net/userfiles/markdown/exp/2023_3/24080ll1679219138.png)

       1. 从Tensorflow，Pytorch，ONNX等机器学习框架中加载模型，导入层使得TVM可以从ONNX，Tensorflow或Pytorch等框架中提取模型。随着开源项目的不断完善，TVM为每个前端提供的支持水平都在逐渐提高。如果在导入模型过程中存在问题，可以尝试将模型转换到ONNX框架下。

       1. 转换为TVM的高级别模型语言`Relay`。`Relay`表示被引入TVM后的模型，它是一种用于神经网络的函数式语言和中间表示形式(IR)。他能够支持：

          - 传统的数据流样式表示
          - 函数式的作用域和let绑定方式使其成为了一种功能齐全的可分化语言
          - 能够让用户混用两种不同的编程模式

          `Relay`会对模型进行若干高层及的优化，在这之后运行`Relay`融合过程。为了帮助这一转换过程，TVM内置了一个包含众多预定义通用计算的张量操作目录（Tensor Operator Inventory (TOPI)）。

       1. 实现到张量表达式表示形式。实现是指将高级表示形式转换为低级表示形式的过程，在`Relay`融合过程中，模型从高级的`Relay`表示形式实现到较小的子图集表示形式，其中每一个节点都是一个任务。每个任务都是用张量表达式所表示的计算模板的集合。模板的参数可以控制该计算如何在硬件上执行。通过定义张量表达式模板参数来实现的指定计算顺序的过程称为调度。

       1. 通过对每个任务使用`AutoTVM`或`AutoScheduler`搜索最优化的调度策略进行调优。调优是在张量表达式参数空间中搜索针对目标硬件进行优化的过程，通常有若干个可选的优化选项，分别需要不同级别的用户交互过程。优化可选项包括：

          - `AutoTVM`：用户通过指定张量表达式任务或张量表达式子图调度过程的搜索模板。AutoTVM将对模板定义的参数空间进行搜索并且生成优化的配置。AutoTVM需要用户手动从张量操作目录(TOPI)中选择搜索模板。
          - `Ansor/AutoSchedule`：通过使用运算符的TVM张量操作目录，Ansor可以自动搜索优化空间，其对用户干预和指导的需求较少。Ansor也依赖张量表达式模板来指导搜索。

       1. 为模型选择最优配置。调优之后，为每个任务选择一个最优的调度。不管它是AutoTVM还是AutoSchedule，都会生成JSON格式的调度记录，这个步骤引用这些记录来构建一个优化后的模型。

       1. 进一步实现到面向硬件的编译器。在基于调优步骤选择了优化的配置之后，模型就会实现到硬件平台的目标编译器所期望的表示形式。这是最终的代码生成阶段，目的是生成可部署到生产环境中的优化模型。TVM支持许多不同的编译器后端，包括:

          - LLVM，它可以针对任意的微处理器体系结构，包括标准的x86和ARM处理器，AMD GPU和NVPTX和所有LLVM支持的平台进行代码生成。
          - 专门的编译器，如NVCC，他是NVIDIA的编译器。
          - 嵌入式和专门的目标，通过TVM的自带代码(Bring Your Own Codegen，BYOC)框架实现。

       1. 编译成机器代码。在这个过程的最后，面向特定编译器的生成代码可以实现为机器码。

          TVM可以将模型编译成一个可链接的对象模块，然后可以与轻量级的TVM运行版一起运行，该运行版提供了C API来动态加载模型，并提供其他语言（如Python和Rust）的调用点。TVM还可以构建捆绑部署，其中运行版和模型将被组合为一个单独的包。

1. 涉及技能点：

   - 掌握TVM运行环境的配置方法
   - 使用TVM对`darknet`平台生成的模型进行编译

### 实验步骤

1. #### 配置TVM运行环境

   1. 安装gcc9.3环境

      ```sh
      # 检查gcc环境
      gcc -v
      # 若gcc版本不是9.3或者显示无相关命令
      export PATH=/usr/local/gcc-9/bin:$PATH
      export LD_LIBRARY_PATH=/usr/local/gcc-9/lib64
      export MANPATH=/usr/local/gcc-9/share/man:$MANPATH
      # 再次检查gcc环境
      gcc -v
      ```

   1. 配置`llvm`运行环境

      TVM使用`llvm`完成CPU环境下的代码生成，因此，在构建TVM的运行库时，需要保证已完成`llvm`的安装。

      1. 使用预编译包安装

      ```sh
      # 解压llvm11.0.1预编译包
      tar -xvf clang+llvm-11.1.0-x86_64-linux-gnu-ubuntu-16.04.tar.xz
      # 修改解压后的文件夹名称为llvm
      
      # 配置llvm路径
      export PATH=$PATH:/path/to/llvm/bin
      # 检测llvm是否配置成功
      llvm-config
      ```

   1. 安装git

      ```shell
      # 检查是否安装git（如安装请跳过）
      apt-get install git
      ```

   1. 安装Python3.7（已安装可跳过）

      由于TVM仅支持Python3.6以上版本，而当前环境为Python3.5.2，因此，需要安装Python3.7

      ```shell
      # 检查环境中是否有python3.7环境
      python37
      pip37
      # 安装ssl模块
      apt-get install libssl-dev（已安装可跳过）
      # 解压Python3.7源码包到当前文件夹
      tar -xvf Python-3.7.6.tgz
      # 创建安装目录
      mkdir /usr/local/python37
      cd Python-3.7.6
      # 执行配置文件
      ./configure --prefix=/usr/local/python37 --with-ssl
      # 安装
      make && make install
      # 建立软连接
      ln -s /usr/local/python37/bin/python3.7 /usr/bin/python37
      ln -s /usr/local/python37/bin/pip3.7 /usr/bin/pip37
      # 测试是否可用
      python37
      pip37 --version
      ```

   1. 配置相关的Python依赖（已安装可跳过）

      ```sh
      apt-get update
      apt-get install -y gcc libtinfo-dev zlib1g-dev build-essential cmake libedit-dev libxml2-dev
      ```

   1. 修改构建参数

      由于使用`cmake`对库进行构建，因此，需要在构建之前设置相关的参数

      ```shell
      # 解压已有的tvm安装包
      tar -zxvf tvm.tar.gz
      # 进入目录
      cd tvm
      # 创建构建目录
      mkdir build
      # 将配置文件拷贝至目录下
      cp cmake/config.cmake build
      # 编辑build/config.cmake文件中的相关参数
      vi build/config.cmake
      ```

      编辑`build/config.cmake`文件中的相关参数

      ```shell
      # 禁用CUDA(GPU平台)
      set(USE_CUDA OFF)
      # 启用图执行器
      set(USE_GRAPH_EXECUTOR ON)
      # 启用探针程序
      set(USE_PROFILER ON)
      # 配置llvm地址
      set(USE_LLVM ON)
      # 配置VTA模拟器
      set(USE_VTA_FSIM ON)
      ```

      构建tvm运行环境

      ```shell
      cd build
      cmake ..
      make -j4
      ```

      > 注：在自行构建时，3rdparty目录下有多个工程需要从原始仓库中下载并放入其中

   1. 配置TVM的Python运行库环境

      ```shell
      rm -rf /headless/.tvm_test_data #该命令只需运行一次
      export TVM_HOME=/path/to/tvm
      export PYTHONPATH=$TVM_HOME/python:${PYTHONPATH}
      ```

   1. 安装部分Python依赖（已安装可跳过）

      ```shell
      pip37 install scipy
      pip37 install numpy
      pip37 install decorator
      pip37 install attrs
      ```

   至此，TVM环境配置工作完成，可通过

   ```
   python37 -m tvm.driver.tvmc
   ```

   命令确认TVM是否正确安装

1. #### 编译`YOLO-V3`模型

   1. 下载Python依赖库（已完成可跳过）

      ```shell
      pip37 install cffi
      pip37 install opencv-python
      ```

   1. 导入依赖

      ```python
      # numpy and matplotlib
      import numpy as np
      import matplotlib
      matplotlib.use("nbAgg")
      import matplotlib.pyplot as plt
      import sys
      
      # tvm, relay
      import tvm
      from tvm import te
      from tvm import relay
      from ctypes import *
      from tvm.contrib.download import download_testdata
      from tvm.relay.testing.darknet import __darknetffi__
      import tvm.relay.testing.yolo_detection
      import tvm.relay.testing.darknet
      ```

   1. 选择模型

      模型为：“yolov2", "yolov3"或"yolov3-tiny"

      ```python
      # Model name
      MODEL_NAME = "yolov3"
      ```

   1. 下载所需配置文件

      第一次运行需要下载cfg（网络配置文件）和weights（权重文件）文件 由于实验环境无法连接网络，导致相关文件无法从网络上下载，相关文件已经提供（在实验数据中），请修改源代码中相关代码来使程序正确运行

      ```python
      CFG_NAME = MODEL_NAME + ".cfg"
      WEIGHTS_NAME = MODEL_NAME + ".weights"
      REPO_URL = "https://github.com/dmlc/web-data/blob/main/darknet/"
      CFG_URL = REPO_URL + "cfg/" + CFG_NAME + "?raw=true"
      WEIGHTS_URL = "https://pjreddie.com/media/files/" + WEIGHTS_NAME
      
      cfg_path = download_testdata(CFG_URL, CFG_NAME, module="darknet")
      weights_path = download_testdata(WEIGHTS_URL, WEIGHTS_NAME, module="darknet")
      
      # Download and Load darknet library
      if sys.platform in ["linux", "linux2"]:
          DARKNET_LIB = "libdarknet2.0.so"
          DARKNET_URL = REPO_URL + "lib/" + DARKNET_LIB + "?raw=true"
      elif sys.platform == "darwin":
          DARKNET_LIB = "libdarknet_mac2.0.so"
          DARKNET_URL = REPO_URL + "lib_osx/" + DARKNET_LIB + "?raw=true"
      else:
          err = "Darknet lib is not supported on {} platform".format(sys.platform)
          raise NotImplementedError(err)
      
      lib_path = download_testdata(DARKNET_URL, DARKNET_LIB, module="darknet")
      
      DARKNET_LIB = __darknetffi__.dlopen(lib_path)
      net = DARKNET_LIB.load_network(cfg_path.encode("utf-8"), weights_path.encode("utf-8"), 0)
      dtype = "float32"
      batch_size = 1
      
      data = np.empty([batch_size, net.c, net.h, net.w], dtype)
      shape_dict = {"data": data.shape}
      print("Converting darknet to relay functions...")
      mod, params = relay.frontend.from_darknet(net, dtype=dtype, shape=data.shape)
      ```

   1. 将模型实现为`Relay`形式

      ```python
      target = tvm.target.Target("llvm", host="llvm")
      dev = tvm.cpu(0)
      data = np.empty([batch_size, net.c, net.h, net.w], dtype)
      shape = {"data": data.shape}
      print("Compiling the model...")
      with tvm.transform.PassContext(opt_level=3):
          lib = relay.build(mod, target=target, params=params)
      
      [neth, netw] = shape["data"][2:]  # Current image shape is 608x608
      ```

   1. 加载测试图像

      ```python
      test_image = "dog.jpg"
      print("Loading the test image...")
      img_url = REPO_URL + "data/" + test_image + "?raw=true"
      img_path = download_testdata(img_url, test_image, "data")
      
      data = tvm.relay.testing.darknet.load_image(img_path, netw, neth)
      ```

   1. 使用TVM运行版进行运行

      ```python
      from tvm.contrib import graph_executor
      
      m = graph_executor.GraphModule(lib["default"](dev))
      
      # set inputs
      m.set_input("data", tvm.nd.array(data.astype(dtype)))
      # execute
      print("Running the test image...")
      
      # detection
      # thresholds
      thresh = 0.5
      nms_thresh = 0.45
      
      m.run()
      # get outputs
      tvm_out = []
      if MODEL_NAME == "yolov2":
          layer_out = {}
          layer_out["type"] = "Region"
          # Get the region layer attributes (n, out_c, out_h, out_w, classes, coords, background)
          layer_attr = m.get_output(2).asnumpy()
          layer_out["biases"] = m.get_output(1).asnumpy()
          out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
          layer_out["output"] = m.get_output(0).asnumpy().reshape(out_shape)
          layer_out["classes"] = layer_attr[4]
          layer_out["coords"] = layer_attr[5]
          layer_out["background"] = layer_attr[6]
          tvm_out.append(layer_out)
      
      elif MODEL_NAME == "yolov3":
          for i in range(3):
              layer_out = {}
              layer_out["type"] = "Yolo"
              # Get the yolo layer attributes (n, out_c, out_h, out_w, classes, total)
              layer_attr = m.get_output(i * 4 + 3).asnumpy()
              layer_out["biases"] = m.get_output(i * 4 + 2).asnumpy()
              layer_out["mask"] = m.get_output(i * 4 + 1).asnumpy()
              out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
              layer_out["output"] = m.get_output(i * 4).asnumpy().reshape(out_shape)
              layer_out["classes"] = layer_attr[4]
              tvm_out.append(layer_out)
      
      elif MODEL_NAME == "yolov3-tiny":
          for i in range(2):
              layer_out = {}
              layer_out["type"] = "Yolo"
              # Get the yolo layer attributes (n, out_c, out_h, out_w, classes, total)
              layer_attr = m.get_output(i * 4 + 3).asnumpy()
              layer_out["biases"] = m.get_output(i * 4 + 2).asnumpy()
              layer_out["mask"] = m.get_output(i * 4 + 1).asnumpy()
              out_shape = (layer_attr[0], layer_attr[1] // layer_attr[0], layer_attr[2], layer_attr[3])
              layer_out["output"] = m.get_output(i * 4).asnumpy().reshape(out_shape)
              layer_out["classes"] = layer_attr[4]
              tvm_out.append(layer_out)
              thresh = 0.560
      
      # do the detection and bring up the bounding boxes
      img = tvm.relay.testing.darknet.load_image_color(img_path)
      _, im_h, im_w = img.shape
      dets = tvm.relay.testing.yolo_detection.fill_network_boxes(
          (netw, neth), (im_w, im_h), thresh, 1, tvm_out
      )
      last_layer = net.layers[net.n - 1]
      tvm.relay.testing.yolo_detection.do_nms_sort(dets, last_layer.classes, nms_thresh)
      
      coco_name = "coco.names"
      coco_url = REPO_URL + "data/" + coco_name + "?raw=true"
      font_name = "arial.ttf"
      font_url = REPO_URL + "data/" + font_name + "?raw=true"
      coco_path = download_testdata(coco_url, coco_name, module="data")
      font_path = download_testdata(font_url, font_name, module="data")
      
      with open(coco_path) as f:
          content = f.readlines()
      
      names = [x.strip() for x in content]
      
      tvm.relay.testing.yolo_detection.show_detections(img, dets, thresh, names, last_layer.classes)
      tvm.relay.testing.yolo_detection.draw_detections(
          font_path, img, dets, thresh, names, last_layer.classes
      )
      plt.imshow(img.transpose(1, 2, 0))
      plt.savefig('detected.jpg')
      ```

### 问题思考

1. 截图粘贴TVM成功配置的截图及YOLO算法实验结果

1. 任选一个在公开数据集上进行训练的神经网络模型，仿照上面实验步骤使用TVM运行。截图粘贴运行结果，说明模型结构（可使用可视化工具）以及数据集。

   ### 参考资料

- TVM：https://tvm.apache.org/docs/index.html