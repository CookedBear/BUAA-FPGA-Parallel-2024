### 1. 实验2-1：深度学习基础

### 实验名称

深度学习基础

### 实验目的

1. 了解深度学习基本原理
1. 了解如何搭建深度学习模型
1. 使用YOLO3实现目标检测

### 实验任务

1. 使用卷积神经网络进行图像识别
1. 使用yolov3进行图片中的目标检测

### 实验结果

![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151550190.jpg)

### 实验分析

1. 涉及知识点：

   1. #### 深度学习简介

      **深度学习**（DL，Deep Learning）是**机器学习**（ML，Machine Learning）领域中一个新的研究方向，它被引入机器学习使其更接近于最初的目标——**人工智能**（AI，Artificial Intelligence）。

      深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字，图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。 深度学习是一个复杂的机器学习算法，在语音和图像识别方面取得的效果，远远超过先前相关技术。

      深度学习在**搜索技术**，**数据挖掘**，**机器学习**，**机器翻译**，**自然语言处理**，**多媒体学习**，**语音**，**推荐和个性化技术**，以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动，解决了很多复杂的模式识别难题，使得人工智能相关技术取得了很大进步。

   1. #### 神经网络

      **人工神经网络**（Artificial Neural Network，即ANN），是20世纪80 年代以来人工智能领域兴起的研究热点。它从信息处理角度对人脑神经元网络进行抽象， 建立某种简单模型，按不同的连接方式组成不同的网络。在工程与学术界也常直接简称为神经网络或类神经网络。神经网络是一种运算模型，由大量的节点（或称神经元）之间相互联接构成。每个节点代表一种特定的输出函数，称为**激励函数**（activation function）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重，这相当于人工神经网络的记忆。网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达。

      1. ##### M-P神经元模型

         M-P神经元是最基本的神经网络网络单元，其模型如下所示：

         ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151550536.jpg)

         其中x只能为0或1。上图中的函数f的图像如下所示：

         ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151550185.jpg)

         因此，M-P模型的工作原理为：当所有的输入与对应的连接权重的乘积之和大于阈值T时，y输出为1，否则输出为0。

      1. ##### 感知机

         单层感知机：包含两层神经元:

         （1）输入层（信号传递）

         （2）输出层（M-P神经元，threshold logic unit）

         ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151550796.jpg)

         M-P模型在创建之初，研究者就发现通过手动设置$\omega$和T，可以实现基本的逻辑运算——AND, OR , NOT，然而却不能实现异或。为了解决这一问题提出两层感知机结构，在输入层和输出层之间包含一层隐藏神经元。

         ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151551384.jpg)

      1. ##### 感知机学习方法

         对于给定的训练数据集$(x,y)$，若当前感知机的输出为$\hat{y}\leftarrow y=f(\sum\limits_{i}\omega_ix_i-\theta)$，则感知机将根据误差对权重做如下调整：

         $$
         \omega_i=\omega_i+\Delta\omega_i\\
         \Delta\omega_i=\eta(y-\hat{y})x_i
      $$
         其中 $\eta\in(0,1)$，称为学习率。
      
         使用**反向传播算法**（BP，back propagation）训练多层感知机，共分为两个阶段：
      
         阶段1：前向阶段。输入信号层层向前传播，其影响限制在激活隐藏神经元以及输出神经元中。
      
         阶段2：反向阶段。通过计算网络的输出与期望之间的误差，逐层反向对网络权值进行修正。
      
      1. ##### 反向传播算法：Back Propagation
      
         ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151557208.jpg)
      
         如上图所示，为一个简单的神经网络示例。其中i为输入神经元，h为隐藏神经元，o为输出神经元，b为偏置(bias)。其前向传播计算方式为：
      $$
      net_{h1}=i_i\omega_1+i_2\omega_2+b_1\\
         out_{h1}=sigmoid(net_{h1})
      $$
         其中 $out_{h1}$ 为用于下一层输入的值。其他神经元的计算方式类似。
      
         训练时首先对神经网络进行初始化。首先使用训练数据初始化输入神经元和输出神经元。然后初始化权重（包括 $\omega$ 和b)，一般使用随机值进行初始化。初始化完成后，进行前向传播计算。
      
         完成前向传播计算后，计算均方误差：
      $$
      E_{tot}=\sum\frac 1 2(target-output)^2\\
         E_{o1}=\frac 1 2(target_{o1}-out_{o1})^2\\
      E_{o2}=\frac 1 2(target_{o2}-out_{o2})^2
      $$
      其中target为训练数据中给出的各个输出神经元的期望值，output为前向传播计算出的值。
      
      随后进行反向传播计算：考虑 $E_{tot}$ 受权重 $\omega_5$ 影响的敏感程度：
      $$
         \frac{\partial E_{tot}}{\partial\omega_5}=\frac{\partial E_{tot}}{\partial out_{o1}}\times\frac{\partial out_{o1}}{\partial net_{o1}}\times\frac{\partial net_{o1}}{\partial\omega_5}
      $$
         设置学习率 $\eta$，以负梯度方向更新权重 $\omega_5$：
      $$
      \omega_5^+=\omega_5-\eta\times\frac{\partial E_{tot}}{\partial\omega_5}
      $$
      同理可以获得 $\omega_6^+,\omega_7^+,\omega_8^+$
      
      再考虑 $E_{tot}$ 受权重 $\omega_1$ 影响的敏感程度：
      $$
         \frac{\partial E_{tot}}{\partial\omega_1}=\frac{\partial E_{tot}}{\partial out_{h1}}\times\frac{\partial out_{h1}}{\partial net_{h1}}\times\frac{\partial net_{h1}}{\partial\omega_1}\\
      \frac{\partial E_{tot}}{\partial out_{h1}}=\frac{\partial E_{o1}}{\partial out_{h1}}+\frac{\partial E_{o2}}{\partial out_{h1}}\\
         \frac{\partial E_{o1}}{\partial out_{h1}}=\frac{\partial E_{o1}}{\partial net_{o1}}\times\frac{\partial net_{o1}}{\partial out_{h1}}\\
      \frac{\partial E_{o1}}{\partial net_{h1}}=\frac{\partial E_{o1}}{\partial out_{o1}}\times\frac{\partial out_{o1}}{\partial net_{h1}}\\
         \frac{\partial net_{o1}}{\partial out_{h1}}=\omega_5\\
      \frac{\partial net_{h1}}{\partial\omega_1}=i_1\\
         \frac{\partial out_{h1}}{\partial net_{h1}}=out_{h1}(1-out_{h1})(sigmoid求导得到)
      $$
         以负梯度方向更新权重：
      $$
      \omega_1^+=\omega_1-\eta\times\frac{\partial E_{tot}}{\partial\omega_1}
         $$
      同理可以求得 $\omega_2^+,\omega_3^+,\omega_4^+$
      
   1. ##### 深度神经网络（DNN）
   
      包括全连接神经网络，卷积神经网络，循环神经网络等。
   
      深度神经网络一般包含两个阶段，分别是训练阶段和推断阶段。训练阶段训练网络中的权值。推断阶段根据训练好的网络权值来计算输出结果。
   
1. #### 全连接神经网络
   
   ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151609133.jpg)
   
   前面已经提到，简单的单层感知机能够实现AND，OR，NOT等逻辑，这其实是一种判别问题：
   
   ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151609579.jpg)
   
   如图所示AND，OR和NOT均是线性可分的，因此使用单层感知机即可解决，而XOR则至少需要两层感知机。那么对于更复杂的情况呢？一般我们认为，三层神经网络可以逼近任何一个非线性函数。因此，存在一种观点认为，只要能够将问题约化为函数，就可以用神经网络解决。典型的如分类问题，就可以用神经网络解决。
   
1. #### 激活函数
   
   前面在介绍神经网络的前向传播计算时，出现了一个名为sigmoid的函数。这类函数称为激活函数。数据的分布绝大多数是非线性的，而一般神经网络的计算是线性的，引入激活函数，是在神经网络中引入非线性，强化网络的学习能力。所以激活函数的最大特点就是非线性。
   
   除sigmoid之外，还有几个常用的激活函数，如`ReLU`，`tanh`，`Leaky-ReLU`等。不同的激活函数，根据其特点，应用也不同。`Sigmoid`和`tanh`的特点是将输出限制在(0,1)和(-1,1)之间，说明`Sigmoid`和`tanh`适合做概率值的处理，例如LSTM中的各种门；而`ReLU`就不行，因为`ReLU`无最大值限制，可能会出现很大值。同样，根据`ReLU`的特征，`Relu`适合用于深层网络的训练，而`Sigmoid`和`tanh`则不行，因为它们会出现梯度消失。
   
1. #### 卷积神经网络（CNN）
   
   卷积神经网络是一种不同形式的神经网络，常用于图像处理等方面。
   
   1. ##### 卷积（Convolution）
   
      ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151610489.jpg)
   
      如图所示，最左边一列为输入图像（图像尺寸为3x5x5，其中3称为通道数channel），左边第二列和第三列为卷积核（单个卷积核尺寸为3x3x3），最右边一列为输出。在进行卷积计算之前，首先进行padding操作，即在输入图像周围补0，如图中所示，padding大小为（1，1）（横向补1格，纵向补1格），这种操作可以起到调整输出尺寸的作用。随后进行卷积计算，将卷积核覆盖在输入图像的某个位置上，将对应位置的值相乘，并将27个乘积加和，即可得到输出的一个值。随后将卷积核移动一定距离，称之为步长stride，如图中所示，步长为（2，2）（横向移动2格，纵向移动2格）。然后再次进行卷积计算，得到输出的第二个值。重复以上步骤，即可完成全部卷积计算。其中输出的通道数由卷积核的数量决定。
   
      卷积完成后，一般使用激活函数对输出进行处理。
   
   1. ##### 池化（Pooling）
   
      池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。
   
      ![实验2-1：深度学习基础](https://cookedbear-2003-1307884465.cos.ap-beijing.myqcloud.com/NotePics/202403151610410.jpg)
   
      如上图所示，为池化的计算方式。以最大池化为例，在一定区域内（图中为2x2）选出最大的值，作为输出。然后将所选区域移动一段距离（称之为步长），重复上述步骤。

- 涉及技能点：
  - 使用卷积神经网络进行图像识别
  - 使用yolov3进行图片中的目标检测

### 实验步骤

1. #### 使用卷积神经网络进行图像识别

   使用`PyTorch`搭建一个简单的卷积神经网络模型，并实现对手写数字的识别

   1. ##### 下载数据集

      在`http://yann.lecun.com/exdb/mnist/`下载`MNIST`数据集，`MNIST`数据集包含60000张训练图片和10000张测试图片。

      > 本次实验将提供所需要数据集的二进制文件

   1. ##### 导入所需要的包

      ```python
      import torch
      import torchvision
      import torchvision.transforms as transforms
      import torch.nn as nn
      import torch.nn.functional as F
      import torch.optim as optim
      import numpy as np
      import struct
      ```

   1. ##### 读取数据集

      ```python
      train_images_idx3_ubyte_file = 'train-images-idx3-ubyte' # 训练图片数据
      train_labels_idx1_ubyte_file = 'train-labels-idx1-ubyte' # 训练标签数据
      test_images_idx3_ubyte_file = 't10k-images-idx3-ubyte'   # 测试图片数据
      test_labels_idx1_ubyte_file = 't10k-labels-idx1-ubyte'   # 测试标签数据
      
      def decode_idx3_ubyte(idx3_ubyte_file):
          bin_data = open(idx3_ubyte_file, 'rb').read()
          offset = 0
          fmt_header = '>iiii' 
          magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)
          image_size = num_rows * num_cols
          offset += struct.calcsize(fmt_header) 
          fmt_image = '>' + str(image_size) + 'B'  
          images = np.empty((num_images, num_rows, num_cols))
          for i in range(num_images):
              images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))
              offset += struct.calcsize(fmt_image)
          return images
      
      def decode_idx1_ubyte(idx1_ubyte_file):
          bin_data = open(idx1_ubyte_file, 'rb').read()
          offset = 0
          fmt_header = '>ii'
          magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)
          offset += struct.calcsize(fmt_header)
          fmt_image = '>B'
          labels = np.empty(num_images)
          for i in range(num_images):
              labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]
              offset += struct.calcsize(fmt_image)
          return labels
      
      def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):
          return decode_idx3_ubyte(idx_ubyte_file)
      def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):
          return decode_idx1_ubyte(idx_ubyte_file)
      def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):
          return decode_idx3_ubyte(idx_ubyte_file)
      def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):
          return decode_idx1_ubyte(idx_ubyte_file)
      
      train_images = load_train_images()
      train_labels = load_train_labels()
      test_images = load_test_images()
      test_labels = load_test_labels()
      
      train_images = np.expand_dims(train_images, axis=1) / 255.0    #数据预处理
      train_labels = train_labels.astype('int')
      test_images = np.expand_dims(test_images, axis=1) / 255.0
      test_labels = test_labels.astype('int')
      ```

   1. ##### 搭建神经网络

      ```python
      class Net(nn.Module):
          def __init__(self):
              super(Net, self).__init__()
              self.conv1 = nn.Conv2d(1, 16, 3, padding=(1,1))
              self.pool1 = nn.MaxPool2d(2, 2)
              self.conv2 = nn.Conv2d(16, 32, 3, padding=(1,1))
              self.pool2 = nn.MaxPool2d(2, 2)
              self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))
              self.globalMaxPool = nn.MaxPool2d(7, 1)
              self.fc = nn.Linear(64, 10)
      
          def forward(self, x):
              x = F.relu(self.conv1(x))        #卷积
              x = self.pool1(x)                #池化
              x = F.relu(self.conv2(x))        #卷积
              x = self.pool2(x)                #池化
              x = F.relu(self.conv3(x))        #卷积
              x = self.globalMaxPool(x)        #池化
              x = x.view(-1, 64*1*1)            #将输出reshape为1维
              x = self.fc(x)                    #全连接
              return x
      ```

   1. ##### 创建神经网络对象和损失函数

      ```python
      net = Net()        #创建Net()对象
      device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    #设置计算设备，cpu或gpu
      net.to(device)
      criterion = nn.CrossEntropyLoss()    #损失函数
      optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)    #优化器
      ```

   1. ##### 训练

      ```python
      epoch_num = 10
      batch_size = 100
      for epoch in range(epoch_num):  # loop over the dataset multiple times
          running_loss = 0.0
          for i in range(int(60000/batch_size)):
              start_index = i*batch_size
              inputs = torch.from_numpy(train_images[start_index:start_index+batch_size])
              labels = torch.from_numpy(train_labels[start_index:start_index+batch_size])
              
              inputs, labels = inputs.to(device), labels.to(device)
              # zero the parameter gradients
              optimizer.zero_grad()
      
              # forward + backward + optimize
              outputs = net(inputs.float())
              
              labels = labels.to(torch.int64)
              
              loss = criterion(outputs, labels)
              loss.backward()
              optimizer.step()
      
              # print statistics
              running_loss += loss.item()
              if i % 50 == 0:    # print every 2000 mini-batches
                  print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 2000))
                  running_loss = 0.0
      ```

   1. ##### 测试准确率

      ```python
      test_num = 1000
      correct = 0
      for i in range(int(test_num/batch_size)):
          start_index = i*batch_size
          test_inputs = torch.from_numpy(test_images[start_index:start_index+batch_size]).float()
          test_inputs = test_inputs.to(device)
          outputs = net(test_inputs)
          _, predicted = torch.max(outputs.data, 1)
          for j in range(batch_size):
              if(predicted[j] == test_labels[start_index+j]):
                  correct += 1
      print("accuracy: ", correct/test_num)
      ```

1. #### 使用yolov3进行图片中的目标检测

   Linux操作系统：

   1. 下载原始工程

      ```shell
      git clone https://github.com/madhawav/YOLO3-4-Py.git
      ```

   1. 下载必要文件

      ```shell
      cd YOLO3-4-Py
      ./tools/download_models.sh      //下载必要的文件（里面需要下载的文件在“相关资料”中均有提供）
            export DARKNET_HOME=/path/to/darknet //设置DARKNET_HOME为darknet库路径
      pip3 install yolo34py            //安装必要依赖
      ```

   1. 准备图片

      将一张图片（以sample.png为例）放在demo文件夹中

   1. 运行

      ```shell
      python3 demo/image_demo.py demo/sample.png
      ```

   Windows操作系统：

    Windows操作系统编译安装darknet框架过程较为繁琐，感兴趣的同学可参考`https://www.jianshu.com/p/f944ebd43f4c`流程进行安装

   > 注：
   >
   > 1. 可使用WSL(Windows Subsystem for Linux)来运行，该系统为Win10下的Linux子系统，使用较为方便
   > 1. 运行此过程需要自行编译安装`darknet`框架运行库并设置环境变量`DARKNET_HOME`，请自行在官网查看安装方法
   > 1. 运行此过程还需安装`opencv`的python环境，为python提供`cv2`模块支持
   > 1. 所需下载的模型文件、配置文件及权重文件均在`darknet`框架中，可按照`download_models.sh`脚本中的要求进行下载和**内容修改**
   > 1. 可通过将`github.com`修改为镜像站点`hub.fastgit.xyz`进行对github的访问

   Python3.7安装流程

   ```shell
   # 安装ssl模块
   apt-get install libssl-dev
   # 下载Python3.7源码包
   wget https://www.python.org/ftp/python/3.7.6/Python-3.7.6.tgz
   # 解压到当前文件夹
   tar -xvf Python-3.7.6.tgz
   # 创建安装目录
   mkdir /usr/local/python37
   cd Python-3.7.6
   # 执行配置文件
   ./configure --prefix=/usr/local/python37 --with-ssl
   # 安装
   make && make install
   # 建立软连接
   ln -s /usr/local/python37/bin/python3.7 /usr/bin/python37
   ln -s /usr/local/python37/bin/pip3.7 /usr/bin/pip37
   # 测试是否可用
   python37
   pip37 --version
   ```

   ### 问题思考

1. 如何通过设置单层感知机的w和T实现`AND`，`OR`和`NOT`

1. 尝试用简洁的方式表示前向传播计算

   > 可以尝试使用矩阵计算的方式表示

1. 参考`使用卷积神经网络进行图像识别`节的代码，自行设计神经网络完成对`cifar10`数据集的分类

   > 准确率达到50%即可
   >
   >  
   >
   > 如果已有相关经验，也可以不必参考文中代码

### 参考资料

- YOLO算法官网：https://pjreddie.com/darknet/yolo/

### 相关资源

- 模型配置文件：[darknet.zip](https://course.educg.net/userfiles/markdown/exp/2022_3/24079ll1647513278.zip)
- Python实现YOLO算法示例工程：[YOLO3-4-Py.zip](https://course.educg.net/userfiles/markdown/exp/2022_3/24079ll1647513373.zip)
- 数据集二进制文件：[dataset.tar.gz](https://course.educg.net/userfiles/markdown/exp/2022_3/8283ll1647591251.gz)
- Python安装包：[Python-3.7.6.tgz](https://course.educg.net/userfiles/markdown/exp/2022_3/8283ll1647606598.tgz)
- 实验报告模板：[实验2-1：实验报告模板.doc](https://course.educg.net/userfiles/markdown/exp/2022_3/8283ll1647829520.doc)